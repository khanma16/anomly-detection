"""
LIVE Traffic Anomaly Detection Web App
=====================================

This app performs REAL network packet capture and ML-based anomaly detection.
"""

import os
import logging
import threading
import time
import queue
import smtplib
import yaml
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime
from pathlib import Path
from flask import Flask, jsonify, render_template_string, request
import joblib
import numpy as np
import pandas as pd
from collections import deque

# Packet capture imports
try:
    import pyshark
    PYSHARK_AVAILABLE = True
except ImportError:
    PYSHARK_AVAILABLE = False

try:
    from scapy.all import sniff, IP, TCP, UDP, ICMP
    SCAPY_AVAILABLE = True
except ImportError:
    SCAPY_AVAILABLE = False

# ML imports
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load configuration
try:
    with open('config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    logger.info("Loaded configuration from config.yaml")
except Exception as e:
    logger.error(f"Failed to load config.yaml: {e}")
    config = {}

# Create Flask app
app = Flask(__name__)

# Email configuration from config.yaml
EMAIL_CONFIG = {
    'enabled': True,  # Enable email alerts since config is provided
    'smtp_server': config.get('email', {}).get('smtp_server', 'smtp.gmail.com'),
    'smtp_port': config.get('email', {}).get('smtp_port', 587),
    'email': config.get('email', {}).get('sender_email', 'your_email@gmail.com'),
    'password': config.get('email', {}).get('sender_password', 'your_password'),
    'to_email': config.get('email', {}).get('recipient_email', 'alerts@yourdomain.com'),
    'subject_template': config.get('email', {}).get('subject_template', 'ALERT: Network Anomaly Detected'),
    'body_template': config.get('email', {}).get('body_template', 'Network anomaly detected at {timestamp}')
}

# Global variables for REAL detection
detection_system = {
    'is_running': False,
    'interface': 'lo',  # Default to loopback for safety
    'packet_queue': queue.Queue(maxsize=1000),
    'models': {},
    'scaler': None,
    'stats': {
        'total_packets': 0,
        'anomalies_detected': 0,
        'start_time': None,
        'recent_anomalies': deque(maxlen=50),
        'packet_rate': deque(maxlen=60),  # Last 60 seconds
        'anomaly_scores': deque(maxlen=100)
    }
}

def convert_numpy_types(obj):
    """Convert numpy types to Python native types for JSON serialization"""
    if isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    return obj

def send_email_alert(alert_data):
    """Send email alert for detected anomaly"""
    if not EMAIL_CONFIG['enabled']:
        logger.warning("Email alerts are disabled. Skipping email for anomaly.")
        return

    try:
        # Create message
        msg = MIMEMultipart()
        msg['From'] = EMAIL_CONFIG['email']
        msg['To'] = EMAIL_CONFIG['to_email']
        msg['Subject'] = EMAIL_CONFIG['subject_template'].format(timestamp=alert_data['timestamp'])
        
        # Email body
        body = EMAIL_CONFIG['body_template'].format(timestamp=alert_data['timestamp']) + """

REAL-TIME NETWORK ANOMALY ALERT
==============================

Time: {timestamp}
Source: {src_ip}:{src_port}
Destination: {dst_ip}:{dst_port}
Protocol: {protocol}
Packet Size: {packet_size} bytes

DETECTION DETAILS:
- Confidence Score: {max_score:.3f}
- Models Triggered: {models_triggered}
- Processing Latency: {latency_ms:.2f}ms

This alert was generated by your Live Network Anomaly Detection System.
Please investigate this suspicious activity immediately.

System: Live Packet Capture with Real ML Models
Interface: {interface}
""".format(
            timestamp=alert_data['timestamp'],
            src_ip=alert_data['src_ip'],
            src_port=alert_data['src_port'],
            dst_ip=alert_data['dst_ip'],
            dst_port=alert_data['dst_port'],
            protocol=alert_data['protocol'].upper(),
            packet_size=alert_data['packet_size'],
            max_score=alert_data['max_score'],
            models_triggered=', '.join(alert_data['models_triggered']),
            latency_ms=alert_data['latency_ms'],
            interface=detection_system['interface']
        )
        
        msg.attach(MIMEText(body, 'plain'))
        
        # Send email
        server = smtplib.SMTP(EMAIL_CONFIG['smtp_server'], EMAIL_CONFIG['smtp_port'])
        server.starttls()
        server.login(EMAIL_CONFIG['email'], EMAIL_CONFIG['password'])
        server.send_message(msg)
        server.quit()
        
        logger.info(f"Email alert sent successfully for anomaly from {alert_data['src_ip']}")
        
    except Exception as e:
        logger.error(f"Failed to send email alert: {e}")

def send_comprehensive_report():
    """Send comprehensive email report of all anomalies detected during session"""
    if not EMAIL_CONFIG['enabled']:
        logger.warning("Email alerts are disabled. Skipping comprehensive report.")
        return
    
    stats = detection_system['stats']
    anomalies = list(stats['recent_anomalies'])
    
    if len(anomalies) == 0:
        logger.info("No anomalies detected during session. Skipping email report.")
        return
    
    try:
        # Create message
        msg = MIMEMultipart()
        msg['From'] = EMAIL_CONFIG['email']
        msg['To'] = EMAIL_CONFIG['to_email']
        msg['Subject'] = f"NETWORK SECURITY REPORT - {len(anomalies)} Anomalies Detected"
        
        # Calculate session stats
        session_duration = time.time() - stats['start_time'] if stats['start_time'] else 0
        avg_latency = np.mean([a['latency_ms'] for a in anomalies]) if anomalies else 0
        detection_rate = (stats['anomalies_detected'] / max(stats['total_packets'], 1)) * 100
        
        # Count models triggered
        model_counts = {}
        protocol_counts = {}
        for anomaly in anomalies:
            for model in anomaly['models_triggered']:
                model_counts[model] = model_counts.get(model, 0) + 1
            protocol = anomaly['protocol']
            protocol_counts[protocol] = protocol_counts.get(protocol, 0) + 1
        
        # Email body
        body = f"""
COMPREHENSIVE NETWORK SECURITY REPORT
=====================================

SESSION SUMMARY:
- Session Duration: {session_duration/60:.1f} minutes
- Total Packets Processed: {stats['total_packets']:,}
- Anomalies Detected: {stats['anomalies_detected']}
- Detection Rate: {detection_rate:.2f}%
- Average ML Processing Time: {avg_latency:.2f}ms
- Interface Monitored: {detection_system['interface']}

MODEL PERFORMANCE:
"""
        for model, count in sorted(model_counts.items()):
            body += f"- {model.replace('_', ' ').title()}: {count} detections\n"
        
        body += f"""
PROTOCOL BREAKDOWN:
"""
        for protocol, count in sorted(protocol_counts.items()):
            body += f"- {protocol.upper()}: {count} anomalies\n"
        
        body += f"""

DETAILED ANOMALY LOG:
====================

"""
        
        # Add detailed anomaly information
        for i, anomaly in enumerate(anomalies[-20:], 1):  # Last 20 anomalies
            body += f"""
ANOMALY #{i}
Time: {anomaly['timestamp']}
Source: {anomaly['src_ip']}:{anomaly['src_port']} → {anomaly['dst_ip']}:{anomaly['dst_port']}
Protocol: {anomaly['protocol'].upper()}
Packet Size: {anomaly['packet_size']} bytes
Confidence Score: {anomaly['max_score']:.3f}
Models Triggered: {', '.join(anomaly['models_triggered'])}
Processing Time: {anomaly['latency_ms']:.2f}ms
{'='*50}
"""
        
        if len(anomalies) > 20:
            body += f"\n... and {len(anomalies) - 20} more anomalies (showing last 20)\n"
        
        body += f"""

RECOMMENDATIONS:
- Review high-confidence anomalies (score > 0.8) immediately
- Investigate repeated source IPs for potential attacks
- Monitor {max(protocol_counts, key=protocol_counts.get, default='N/A')} traffic closely (highest anomaly count)
- Consider implementing additional security measures for detected patterns

This report was generated by your Live Network Anomaly Detection System.
Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

System: Live Packet Capture with Real ML Models
Interface: {detection_system['interface']}
Models Used: {', '.join(model_counts.keys())}
"""
        
        msg.attach(MIMEText(body, 'plain'))
        
        # Send email
        server = smtplib.SMTP(EMAIL_CONFIG['smtp_server'], EMAIL_CONFIG['smtp_port'])
        server.starttls()
        server.login(EMAIL_CONFIG['email'], EMAIL_CONFIG['password'])
        server.send_message(msg)
        server.quit()
        
        logger.info(f"Comprehensive security report sent successfully ({len(anomalies)} anomalies)")
        
    except Exception as e:
        logger.error(f"Failed to send comprehensive report: {e}")

class LivePacketCapture:
    """Real-time packet capture using PyShark or Scapy"""
    
    def __init__(self, interface='lo'):
        self.interface = interface
        self.is_capturing = False
        self.capture_thread = None
        
        # Feature mapping for consistent preprocessing
        self.feature_columns = [
            'duration', 'protocol_type', 'service', 'flag', 'src_bytes',
            'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',
            'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',
            'su_attempted', 'num_root', 'num_file_creations', 'num_shells',
            'num_access_files', 'num_outbound_cmds', 'is_host_login',
            'is_guest_login', 'count', 'srv_count', 'serror_rate',
            'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',
            'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',
            'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',
            'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',
            'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',
            'dst_host_srv_serror_rate', 'dst_host_rerror_rate',
            'dst_host_srv_rerror_rate'
        ]
    
    def extract_features_from_packet(self, packet):
        """Extract features from network packet for NSL-KDD format"""
        try:
            features = {}
            
            # Basic packet analysis
            if hasattr(packet, 'length'):
                packet_size = int(packet.length)
            else:
                packet_size = len(str(packet))
            
            # Protocol analysis
            protocol_type = 'icmp'  # default
            service = 'other'
            src_port = 0
            dst_port = 0
            
            if hasattr(packet, 'tcp'):
                protocol_type = 'tcp'
                src_port = int(packet.tcp.srcport) if hasattr(packet.tcp, 'srcport') else 0
                dst_port = int(packet.tcp.dstport) if hasattr(packet.tcp, 'dstport') else 0
                
                # Determine service based on port
                if dst_port == 80 or src_port == 80:
                    service = 'http'
                elif dst_port == 443 or src_port == 443:
                    service = 'https'
                elif dst_port == 22 or src_port == 22:
                    service = 'ssh'
                elif dst_port == 53 or src_port == 53:
                    service = 'domain'
                elif dst_port == 21 or src_port == 21:
                    service = 'ftp'
                
            elif hasattr(packet, 'udp'):
                protocol_type = 'udp'
                src_port = int(packet.udp.srcport) if hasattr(packet.udp, 'srcport') else 0
                dst_port = int(packet.udp.dstport) if hasattr(packet.udp, 'dstport') else 0
                
                if dst_port == 53 or src_port == 53:
                    service = 'domain'
            
            # Create feature vector matching NSL-KDD format
            # Note: Many features can't be extracted from single packets,
            # so we use approximations based on packet characteristics
            
            features = {
                'duration': 0,  # Single packet has no duration
                'protocol_type': protocol_type,
                'service': service,
                'flag': 'SF',  # Assume successful connection
                'src_bytes': packet_size if dst_port != 0 else 0,
                'dst_bytes': packet_size if src_port != 0 else 0,
                'land': 1 if hasattr(packet, 'ip') and packet.ip.src == packet.ip.dst else 0,
                'wrong_fragment': 0,
                'urgent': 0,
                'hot': 1 if dst_port in [21, 22, 23, 25, 53, 80, 443] else 0,
                'num_failed_logins': 0,
                'logged_in': 1 if dst_port in [22, 23] else 0,
                'num_compromised': 0,
                'root_shell': 0,
                'su_attempted': 0,
                'num_root': 0,
                'num_file_creations': 0,
                'num_shells': 0,
                'num_access_files': 0,
                'num_outbound_cmds': 0,
                'is_host_login': 0,
                'is_guest_login': 0,
                'count': 1,  # This is one connection
                'srv_count': 1,
                'serror_rate': 0,
                'srv_serror_rate': 0,
                'rerror_rate': 0,
                'srv_rerror_rate': 0,
                'same_srv_rate': 1,
                'diff_srv_rate': 0,
                'srv_diff_host_rate': 0,
                'dst_host_count': 1,
                'dst_host_srv_count': 1,
                'dst_host_same_srv_rate': 1,
                'dst_host_diff_srv_rate': 0,
                'dst_host_same_src_port_rate': 1,
                'dst_host_srv_diff_host_rate': 0,
                'dst_host_serror_rate': 0,
                'dst_host_srv_serror_rate': 0,
                'dst_host_rerror_rate': 0,
                'dst_host_srv_rerror_rate': 0
            }
            
            # Add packet metadata
            features['_metadata'] = {
                'timestamp': datetime.now().isoformat(),
                'src_ip': packet.ip.src if hasattr(packet, 'ip') else '0.0.0.0',
                'dst_ip': packet.ip.dst if hasattr(packet, 'ip') else '0.0.0.0',
                'src_port': src_port,
                'dst_port': dst_port,
                'protocol': protocol_type,
                'packet_size': packet_size
            }
            
            return features
            
        except Exception as e:
            logger.error(f"Error extracting features: {e}")
            return None
    
    def start_capture_pyshark(self):
        """Start packet capture using PyShark"""
        try:
            logger.info(f"Starting PyShark capture on interface: {self.interface}")
            capture = pyshark.LiveCapture(interface=self.interface)
            
            for packet in capture.sniff_continuously():
                if not self.is_capturing:
                    break
                
                features = self.extract_features_from_packet(packet)
                if features:
                    if not detection_system['packet_queue'].full():
                        detection_system['packet_queue'].put(features)
                    else:
                        # Remove old packet
                        try:
                            detection_system['packet_queue'].get_nowait()
                            detection_system['packet_queue'].put(features)
                        except queue.Empty:
                            pass
                        
        except Exception as e:
            logger.error(f"PyShark capture error: {e}")
    
    def start_capture_scapy(self):
        """Start packet capture using Scapy"""
        try:
            logger.info(f"Starting Scapy capture on interface: {self.interface}")
            
            def packet_handler(packet):
                if not self.is_capturing:
                    return
                
                # Convert Scapy packet to PyShark-like object for feature extraction
                packet_obj = type('obj', (object,), {})()
                
                if IP in packet:
                    packet_obj.ip = type('obj', (object,), {})()
                    packet_obj.ip.src = packet[IP].src
                    packet_obj.ip.dst = packet[IP].dst
                
                if TCP in packet:
                    packet_obj.tcp = type('obj', (object,), {})()
                    packet_obj.tcp.srcport = packet[TCP].sport
                    packet_obj.tcp.dstport = packet[TCP].dport
                elif UDP in packet:
                    packet_obj.udp = type('obj', (object,), {})()
                    packet_obj.udp.srcport = packet[UDP].sport
                    packet_obj.udp.dstport = packet[UDP].dport
                
                packet_obj.length = len(packet)
                
                features = self.extract_features_from_packet(packet_obj)
                if features:
                    if not detection_system['packet_queue'].full():
                        detection_system['packet_queue'].put(features)
                    else:
                        try:
                            detection_system['packet_queue'].get_nowait()
                            detection_system['packet_queue'].put(features)
                        except queue.Empty:
                            pass
            
            sniff(iface=self.interface, prn=packet_handler, stop_filter=lambda x: not self.is_capturing)
            
        except Exception as e:
            logger.error(f"Scapy capture error: {e}")
    
    def start_capture(self):
        """Start packet capture in background thread"""
        self.is_capturing = True
        
        if PYSHARK_AVAILABLE:
            self.capture_thread = threading.Thread(target=self.start_capture_pyshark, daemon=True)
        elif SCAPY_AVAILABLE:
            self.capture_thread = threading.Thread(target=self.start_capture_scapy, daemon=True)
        else:
            raise RuntimeError("Neither PyShark nor Scapy is available")
        
        self.capture_thread.start()
    
    def stop_capture(self):
        """Stop packet capture"""
        self.is_capturing = False

class RealMLDetector:
    """Real ML model loading and prediction"""
    
    def __init__(self, dataset='nsl_kdd'):
        self.dataset = dataset
        self.models = {}
        self.scaler = None
        self.label_encoders = {}
        self.load_models()
    
    def load_models(self):
        """Load real trained ML models"""
        try:
            models_dir = Path('models')
            
            # Load models
            model_files = {
                'isolation_forest': f'{self.dataset}_isolation_forest.pkl',
                'random_forest': f'{self.dataset}_random_forest.pkl',
                'xgboost': f'{self.dataset}_xgboost.pkl',
                'kmeans': f'{self.dataset}_kmeans.pkl',
                'autoencoder': f'{self.dataset}_autoencoder.pkl'
            }
            
            for model_name, filename in model_files.items():
                model_path = models_dir / filename
                if model_path.exists():
                    self.models[model_name] = joblib.load(model_path)
                    logger.info(f"Loaded {model_name} model")
            
            # Load scaler
            scaler_path = models_dir / f'{self.dataset}_scaler.pkl'
            if scaler_path.exists():
                self.scaler = joblib.load(scaler_path)
                logger.info("Loaded scaler")
            
            # Load autoencoder threshold if exists
            threshold_path = models_dir / f'{self.dataset}_autoencoder_threshold.pkl'
            if threshold_path.exists():
                self.autoencoder_threshold = joblib.load(threshold_path)
                logger.info("Loaded autoencoder threshold")
            
            logger.info(f"Successfully loaded {len(self.models)} models")
            
        except Exception as e:
            logger.error(f"Error loading models: {e}")
    
    def preprocess_features(self, features):
        """Preprocess features for ML models"""
        try:
            # Convert categorical features
            categorical_features = ['protocol_type', 'service', 'flag']
            
            # Create label encoders if not exist
            for feature in categorical_features:
                if feature not in self.label_encoders:
                    self.label_encoders[feature] = LabelEncoder()
                    # Fit with common values
                    if feature == 'protocol_type':
                        self.label_encoders[feature].fit(['tcp', 'udp', 'icmp'])
                    elif feature == 'service':
                        self.label_encoders[feature].fit(['http', 'https', 'ssh', 'ftp', 'domain', 'other'])
                    elif feature == 'flag':
                        self.label_encoders[feature].fit(['SF', 'S0', 'REJ', 'RSTR', 'SH', 'RSTO'])
            
            # Encode categorical features
            processed_features = features.copy()
            for feature in categorical_features:
                try:
                    processed_features[feature] = self.label_encoders[feature].transform([features[feature]])[0]
                except ValueError:
                    # Handle unknown categories
                    processed_features[feature] = 0
            
            # Remove metadata
            if '_metadata' in processed_features:
                del processed_features['_metadata']
            
            # Define feature columns in correct order
            feature_columns = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes',
                       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',
                       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',
                       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',
                       'num_access_files', 'num_outbound_cmds', 'is_host_login',
                       'is_guest_login', 'count', 'srv_count', 'serror_rate',
                       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',
                       'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',
                       'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',
                       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',
                       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',
                       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',
                       'dst_host_srv_rerror_rate']
            
            # Create feature vector
            feature_vector = []
            for col in feature_columns:
                feature_vector.append(processed_features.get(col, 0))
            
            # Scale features using DataFrame to preserve feature names
            if self.scaler:
                # Create DataFrame with proper column names to avoid sklearn warning
                feature_df = pd.DataFrame([feature_vector], columns=feature_columns)
                feature_vector = self.scaler.transform(feature_df)[0]
            
            return feature_vector
            
        except Exception as e:
            logger.error(f"Error preprocessing features: {e}")
            return None
    
    def predict_anomaly(self, features):
        """Predict anomaly using real ML models"""
        try:
            start_time = time.time()
            
            # Preprocess features
            processed_features = self.preprocess_features(features)
            if processed_features is None:
                return None
            
            predictions = {}
            anomaly_detected = False
            max_score = 0
            
            # Isolation Forest
            if 'isolation_forest' in self.models:
                pred = self.models['isolation_forest'].predict([processed_features])[0]
                score = self.models['isolation_forest'].decision_function([processed_features])[0]
                predictions['isolation_forest'] = {'prediction': pred, 'score': float(score)}
                if pred == -1:  # Anomaly
                    anomaly_detected = True
                    max_score = max(max_score, abs(float(score)))
            
            # Random Forest
            if 'random_forest' in self.models:
                pred = self.models['random_forest'].predict([processed_features])[0]
                proba = self.models['random_forest'].predict_proba([processed_features])[0]
                score = proba[1] if len(proba) > 1 else proba[0]
                predictions['random_forest'] = {'prediction': int(pred), 'score': float(score)}
                if pred == 1:  # Anomaly
                    anomaly_detected = True
                    max_score = max(max_score, float(score))
            
            # XGBoost
            if 'xgboost' in self.models:
                pred = self.models['xgboost'].predict([processed_features])[0]
                proba = self.models['xgboost'].predict_proba([processed_features])[0]
                score = proba[1] if len(proba) > 1 else proba[0]
                predictions['xgboost'] = {'prediction': int(pred), 'score': float(score)}
                if pred == 1:  # Anomaly
                    anomaly_detected = True
                    max_score = max(max_score, float(score))
            
            latency_ms = (time.time() - start_time) * 1000
            
            return {
                'anomaly_detected': anomaly_detected,
                'max_score': float(max_score),
                'predictions': predictions,
                'latency_ms': float(latency_ms),
                'models_triggered': [model for model, result in predictions.items() 
                                   if result['prediction'] in [-1, 1]]
            }
            
        except Exception as e:
            logger.error(f"Error in anomaly prediction: {e}")
            return None

# Initialize components
packet_capture = None
ml_detector = None

# HTML Template for Live Demo
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LIVE Network Anomaly Detection</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        .header {
            background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }
        .header h1 { font-size: 2.5em; margin-bottom: 10px; }
        .header .warning {
            background: rgba(255,255,255,0.2);
            padding: 15px;
            border-radius: 10px;
            margin-top: 20px;
            font-weight: bold;
        }
        
        .content { padding: 30px; }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        .stat-card {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            text-align: center;
            border-left: 5px solid #e74c3c;
        }
        .stat-card h3 {
            color: #2c3e50;
            margin-bottom: 10px;
            font-size: 1.1em;
        }
        .stat-value {
            font-size: 2.2em;
            font-weight: bold;
            color: #e74c3c;
            margin-bottom: 5px;
        }
        .status-running { color: #27ae60; }
        .status-stopped { color: #e74c3c; }
        
        .controls {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 10px;
            margin-bottom: 30px;
            border-left: 5px solid #3498db;
        }
        
        .btn {
            padding: 12px 24px;
            margin: 8px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-weight: bold;
            transition: all 0.3s;
        }
        .btn-start { background: #27ae60; color: white; }
        .btn-start:hover { background: #229954; }
        .btn-stop { background: #e74c3c; color: white; }
        .btn-stop:hover { background: #c0392b; }
        
        select, input {
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 4px;
            margin: 8px;
        }
        
        .alerts-section {
            background: white;
            padding: 25px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 20px;
        }
        
        .alert-item {
            padding: 15px;
            border: 1px solid #e9ecef;
            border-radius: 6px;
            margin-bottom: 10px;
            background: #fff5f5;
            border-left: 4px solid #e74c3c;
        }
        
        .real-indicator {
            background: #e74c3c;
            color: white;
            padding: 5px 10px;
            border-radius: 15px;
            font-size: 0.8em;
            font-weight: bold;
            display: inline-block;
            margin-left: 10px;
        }
        
        .warning-box {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            color: #856404;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>LIVE Network Anomaly Detection</h1>
            <p>Real packet capture • Real ML models • Real-time analysis</p>
            <div class="warning">
                WARNING: This performs REAL network monitoring. Use only on networks you own or have permission to monitor.
            </div>
        </div>
        
        <div class="content">            
            <!-- Real-time Stats -->
            <div class="stats-grid">
                <div class="stat-card">
                    <h3>Capture Status <span class="real-indicator">REAL</span></h3>
                    <div id="status" class="stat-value status-stopped">STOPPED</div>
                </div>
                <div class="stat-card">
                    <h3>Packets Captured</h3>
                    <div id="packets" class="stat-value">0</div>
                </div>
                <div class="stat-card">
                    <h3>Anomalies Detected</h3>
                    <div id="anomalies" class="stat-value">0</div>
                </div>
                <div class="stat-card">
                    <h3>Detection Rate</h3>
                    <div id="rate" class="stat-value">0%</div>
                </div>
                <div class="stat-card">
                    <h3>Avg Latency (Real ML)</h3>
                    <div id="latency" class="stat-value">0ms</div>
                </div>
            </div>
            
            <!-- Controls -->
            <div class="controls">
                <h3>Live Capture Controls</h3>
                <button class="btn btn-start" onclick="startCapture()" id="startBtn">
                    Start Live Capture
                </button>
                <button class="btn btn-stop" onclick="stopCapture()" id="stopBtn">
                    Stop Capture
                </button>
                <button class="btn" style="background: #f39c12; color: white;" onclick="sendReport()" id="reportBtn">
                    Send Email Report
                </button>
                <br>
                <label>Interface:</label>
                <select id="interface">
                    <option value="lo">lo (Loopback - Safe)</option>
                    <option value="eth0">eth0 (Ethernet)</option>
                    <option value="wlan0">wlan0 (WiFi)</option>
                    <option value="en0">en0 (macOS Ethernet)</option>
                </select>
                <label>Dataset:</label>
                <select id="dataset">
                    <option value="nsl_kdd">NSL-KDD Models</option>
                    <option value="cicids2017">CICIDS2017 Models</option>
                    <option value="unsw_nb15">UNSW-NB15 Models</option>
                    <option value="ton_iot">TON-IoT Models</option>
                </select>
                <p style="margin-top: 10px; color: #666; font-size: 0.9em;">
                    <strong>Safe Start:</strong> Use "lo" interface to capture local traffic safely.<br>
                </p>
            </div>
            
            <!-- Recent Alerts -->
            <div class="alerts-section">
                <h3>Live Anomaly Alerts <span class="real-indicator">REAL ML</span></h3>
                <div id="alerts-list">
                    <p style="color: #666; font-style: italic;">No anomalies detected yet. Start capture to see live results...</p>
                </div>
            </div>
        </div>
    </div>

    <script>
        let updateInterval;
        
        function updateStats() {
            fetch('/api/live-status')
                .then(response => response.json())
                .then(data => {
                    document.getElementById('status').textContent = data.status.toUpperCase();
                    document.getElementById('status').className = 'stat-value ' + 
                        (data.status === 'running' ? 'status-running' : 'status-stopped');
                    document.getElementById('packets').textContent = data.total_packets;
                    document.getElementById('anomalies').textContent = data.anomalies_detected;
                    document.getElementById('rate').textContent = data.detection_rate.toFixed(1) + '%';
                    document.getElementById('latency').textContent = data.avg_latency.toFixed(1) + 'ms';
                })
                .catch(err => console.log('Status update error:', err));
            
            updateAlerts();
        }
        
        function updateAlerts() {
            fetch('/api/live-alerts')
                .then(response => response.json())
                .then(data => {
                    const list = document.getElementById('alerts-list');
                    if (data.length === 0) {
                        list.innerHTML = '<p style="color: #666; font-style: italic;">No anomalies detected yet. Start capture to see live results...</p>';
                    } else {
                        list.innerHTML = data.slice(-10).reverse().map(alert => {
                            return `<div class="alert-item">
                                <strong>REAL ANOMALY DETECTED</strong><br>
                                <strong>Time:</strong> ${new Date(alert.timestamp).toLocaleString()}<br>
                                <strong>Source:</strong> ${alert.src_ip}:${alert.src_port} → ${alert.dst_ip}:${alert.dst_port}<br>
                                <strong>Protocol:</strong> ${alert.protocol.toUpperCase()}<br>
                                <strong>Models Triggered:</strong> ${alert.models_triggered.join(', ')}<br>
                                <strong>Confidence:</strong> ${(alert.max_score * 100).toFixed(1)}%<br>
                                <strong>Latency:</strong> ${alert.latency_ms.toFixed(1)}ms
                            </div>`;
                        }).join('');
                    }
                })
                .catch(err => console.log('Alerts update error:', err));
        }
        
        function startCapture() {
            const interface = document.getElementById('interface').value;
            const dataset = document.getElementById('dataset').value;
            const startBtn = document.getElementById('startBtn');
            
            startBtn.disabled = true;
            startBtn.textContent = 'Starting Live Capture...';
            
            fetch('/api/start-live-capture', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({interface: interface, dataset: dataset})
            })
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    alert('SUCCESS: ' + data.message);
                    updateInterval = setInterval(updateStats, 2000);
                } else {
                    alert('ERROR: ' + data.error);
                }
                startBtn.disabled = false;
                startBtn.textContent = 'Start Live Capture';
            })
            .catch(err => {
                alert('ERROR: ' + err.message);
                startBtn.disabled = false;
                startBtn.textContent = 'Start Live Capture';
            });
        }
        
        function stopCapture() {
            fetch('/api/stop-live-capture', {method: 'POST'})
                .then(response => response.json())
                .then(data => {
                    alert('STOPPED: ' + data.message);
                    if (updateInterval) {
                        clearInterval(updateInterval);
                    }
                })
                .catch(err => alert('ERROR: ' + err.message));
        }
        
        function sendReport() {
            fetch('/api/send-report', {method: 'POST'})
                .then(response => response.json())
                .then(data => {
                    if (data.success) {
                        alert('EMAIL SENT: ' + data.message);
                    } else {
                        alert('ERROR: ' + data.error);
                    }
                })
                .catch(err => alert('ERROR: ' + err.message));
        }
        
        // Initial load
        updateStats();
        setInterval(() => {
            if (!updateInterval) {
                updateStats();
            }
        }, 5000);
    </script>
</body>
</html>
"""

# Flask Routes
@app.route('/')
def home():
    """Main live demo page"""
    return render_template_string(HTML_TEMPLATE)

@app.route('/api/live-status')
def live_status():
    """Get live capture status"""
    stats = detection_system['stats']
    return jsonify({
        'status': 'running' if detection_system['is_running'] else 'stopped',
        'total_packets': stats['total_packets'],
        'anomalies_detected': stats['anomalies_detected'],
        'detection_rate': (stats['anomalies_detected'] / max(stats['total_packets'], 1)) * 100,
        'avg_latency': np.mean(list(stats['anomaly_scores'])) if stats['anomaly_scores'] else 0,
        'uptime': time.time() - stats['start_time'] if stats['start_time'] else 0
    })

@app.route('/api/live-alerts')
def live_alerts():
    """Get recent live anomaly alerts"""
    # Convert all numpy types to Python types for JSON serialization
    alerts = []
    for alert in detection_system['stats']['recent_anomalies']:
        alerts.append(convert_numpy_types(alert))
    return jsonify(alerts)

@app.route('/api/send-report', methods=['POST'])
def send_report():
    """Manually send comprehensive report"""
    try:
        email_thread = threading.Thread(target=send_comprehensive_report, daemon=True)
        email_thread.start()
        return jsonify({'success': True, 'message': 'Comprehensive report being sent'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/start-live-capture', methods=['POST'])
def start_live_capture():
    """Start real packet capture and ML detection"""
    global packet_capture, ml_detector
    
    try:
        data = request.json
        interface = data.get('interface', 'lo')
        dataset = data.get('dataset', 'nsl_kdd')
        
        if detection_system['is_running']:
            return jsonify({'success': False, 'error': 'Capture already running'})
        
        # Check requirements
        if not PYSHARK_AVAILABLE and not SCAPY_AVAILABLE:
            return jsonify({'success': False, 'error': 'Neither PyShark nor Scapy available. Install with: pip install pyshark scapy'})
        
        # Initialize components
        packet_capture = LivePacketCapture(interface)
        ml_detector = RealMLDetector(dataset)
        
        if len(ml_detector.models) == 0:
            return jsonify({'success': False, 'error': f'No models found for dataset {dataset}'})
        
        # Reset stats
        detection_system['is_running'] = True
        detection_system['interface'] = interface
        stats = detection_system['stats']
        stats['total_packets'] = 0
        stats['anomalies_detected'] = 0
        stats['start_time'] = time.time()
        stats['recent_anomalies'].clear()
        
        # Start capture and processing
        packet_capture.start_capture()
        processing_thread = threading.Thread(target=process_packets, daemon=True)
        processing_thread.start()
        
        logger.info(f"Started live capture on {interface} with {dataset} models")
        return jsonify({
            'success': True, 
            'message': f'Live capture started on {interface} with {len(ml_detector.models)} {dataset} models'
        })
        
    except Exception as e:
        logger.error(f"Error starting live capture: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/stop-live-capture', methods=['POST'])
def stop_live_capture():
    """Stop live capture"""
    global packet_capture
    
    detection_system['is_running'] = False
    if packet_capture:
        packet_capture.stop_capture()
    
    # Send comprehensive email report
    email_thread = threading.Thread(target=send_comprehensive_report, daemon=True)
    email_thread.start()
    
    logger.info("Live capture stopped and comprehensive report being sent")
    return jsonify({'message': 'Live capture stopped and comprehensive report being sent'})

def process_packets():
    """Process captured packets with real ML models"""
    global ml_detector
    
    logger.info("Starting real-time packet processing")
    
    while detection_system['is_running']:
        try:
            # Get packet from queue
            packet_features = detection_system['packet_queue'].get(timeout=1)
            
            stats = detection_system['stats']
            stats['total_packets'] += 1
            
            # Run real ML prediction
            result = ml_detector.predict_anomaly(packet_features)
            
            if result and result['anomaly_detected']:
                stats['anomalies_detected'] += 1
                
                # Create alert
                metadata = packet_features.get('_metadata', {})
                alert = {
                    'timestamp': metadata.get('timestamp', datetime.now().isoformat()),
                    'src_ip': metadata.get('src_ip', 'unknown'),
                    'dst_ip': metadata.get('dst_ip', 'unknown'),
                    'src_port': metadata.get('src_port', 0),
                    'dst_port': metadata.get('dst_port', 0),
                    'protocol': metadata.get('protocol', 'unknown'),
                    'packet_size': metadata.get('packet_size', 0),
                    'max_score': float(result['max_score']),
                    'models_triggered': result['models_triggered'],
                    'latency_ms': float(result['latency_ms'])
                }
                
                stats['recent_anomalies'].append(alert)
                stats['anomaly_scores'].append(result['latency_ms'])
                
                logger.info(f"REAL ANOMALY DETECTED: {alert['src_ip']} -> {alert['dst_ip']} (Score: {result['max_score']:.3f})")
                
                # NOTE: Individual email alerts disabled - comprehensive report sent on stop capture
            
        except queue.Empty:
            continue
        except Exception as e:
            logger.error(f"Error processing packet: {e}")

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8001))
    
    logger.info(f"Starting LIVE Network Anomaly Detection on port {port}")
    logger.info("WARNING: This performs REAL network monitoring")
    
    app.run(host='0.0.0.0', port=port, debug=False, threaded=True) 